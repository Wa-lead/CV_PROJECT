{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(CCCC(=O)Nc1cccc(Br)c1)NNC=C1C=C([N+](=O)[O...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSCCC(C(=O)Nc1ccc2c(c1)OCCO2)N1Cc2ccccc2C1=O</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=C(C)Cn1c(N(CCO)Cc2ccccc2)nc2c1c(=O)[nH]c(=O)n2C</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fc1ccccc1COc1ccc(Br)cc1CNCC1CCCO1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cc1ccc(C)c(CN2C(=O)c3ccccc3S(=O)(=O)c3ccc(C(=O...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  label\n",
       "0  O=C(CCCC(=O)Nc1cccc(Br)c1)NNC=C1C=C([N+](=O)[O...    1.0\n",
       "1       CSCCC(C(=O)Nc1ccc2c(c1)OCCO2)N1Cc2ccccc2C1=O    0.0\n",
       "2  C=C(C)Cn1c(N(CCO)Cc2ccccc2)nc2c1c(=O)[nH]c(=O)n2C    0.0\n",
       "3                  Fc1ccccc1COc1ccc(Br)cc1CNCC1CCCO1    1.0\n",
       "4  Cc1ccc(C)c(CN2C(=O)c3ccccc3S(=O)(=O)c3ccc(C(=O...    1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from chemception.chemception import Chemception\n",
    "from chemception.Featurizer import ChemCeptionizer\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "train_df = pd.read_csv('data/train_aid686978_0.3.csv')\n",
    "# train_df = train_df.sample(frac=0.2)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SMILES` are a way to represent molecules as strings. This represenation is a standard in the Chemistry community and is usually parsed to other representaions of the molecule. For example, the `RDKit` library can parse SMILES to a `Mol` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x29478f890>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chem.MolFromSmiles(train_df['smiles'].iloc[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this represntation as a first step for our featurization. We will use the `RDKit` library to parse the SMILES to a `Mol` object for all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"mol\"] = train_df[\"smiles\"].apply(Chem.MolFromSmiles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The featurization process is the backbone of the paper we adopted, the paper chose certain feature that well describe the molecule and used them as features for the model. Which is inline with what we have learned in picking features for our data.\n",
    "\n",
    "Since we are using a `CNN` Model, our featurization method will be dependent on an image represtnation of the molecule. However, we do some feature engineering that extract important aspects of the molecule (`bonds order`, `atom types`, `hybridization`, and `gasteiger charges`) and use them as features for our model.\n",
    "\n",
    "\n",
    "![Alt text](images/Featurizer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the featurizer we used, can be found in Featurizer.py\n",
    "featureizer = ChemCeptionizer(embed=20, fuse=True)\n",
    "\n",
    "# Featurize the molecules\n",
    "train_df[\"molimage\"] = train_df[\"mol\"].apply(featureizer.featurize)\n",
    "# pd.to_pickle(train_df, \"train_df.pkl\")\n",
    "\n",
    "# train_df = pd.read_pickle(\"train_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.dropna(inplace=True)\n",
    "# for i in train_df['molimage']:\n",
    "#     f = i.flatten()\n",
    "#     if np.nan in f:\n",
    "#         print(\"nan\")\n",
    "#         break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results of the featurization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_channel(v, channel_ind):\n",
    "#     \"\"\"\n",
    "#     Show a single channel of a 3D numpy array\n",
    "#     \"\"\"\n",
    "#     v_copy = np.zeros(shape=(v.shape[0], v.shape[1], 3))\n",
    "#     if channel_ind >= 3:\n",
    "#         v_copy[:,:,0] = v[:,:,channel_ind]/ np.max(v[:,:,channel_ind])\n",
    "#     else:\n",
    "#         v_copy[:,:,channel_ind] = v[:,:,channel_ind]/ np.max(v[:,:,channel_ind])\n",
    "        \n",
    "#     return v_copy\n",
    "\n",
    "\n",
    "# sample = train_df[\"molimage\"].iloc[1]\n",
    "# plt.imshow(sample)\n",
    "# ch1, ch2, ch3 = show_channel(sample, 0), show_channel(sample, 1), show_channel(sample, 2)\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "# ax[0, 0].imshow(ch1)\n",
    "# ax[0, 1].imshow(ch2)\n",
    "# ax[1, 0].imshow(ch3)\n",
    "# # ax[1, 1].imshow(ch4)\n",
    "# ax[0, 0].set_title(\"Bond Channel\")\n",
    "# ax[0, 1].set_title(\"Atomic Number Channel\")\n",
    "# ax[1, 0].set_title(\"Hybridization Channel\")\n",
    "# # ax[1, 1].set_title(\"Gasteiger Charge Channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Molecule')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_channel(v, channel_ind):\n",
    "    \"\"\"\n",
    "    Show a single channel of a 3D numpy array\n",
    "    \"\"\"\n",
    "    v_copy = np.zeros(shape=(v.shape[0], v.shape[1], 3))\n",
    "    if channel_ind >= 3:\n",
    "        v_copy[:,:,0] = v[:,:,channel_ind]/ np.max(v[:,:,channel_ind])\n",
    "    else:\n",
    "        v_copy[:,:,channel_ind] = v[:,:,channel_ind]/ np.max(v[:,:,channel_ind])\n",
    "        \n",
    "    return v_copy\n",
    "\n",
    "\n",
    "sample = train_df[\"molimage\"].iloc[1]\n",
    "ch1, ch2, ch3 = show_channel(sample, 0), show_channel(sample, 1), show_channel(sample, 2)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 15))\n",
    "ax[0].imshow(sample)\n",
    "ax[1].imshow(ch1)\n",
    "ax[2].imshow(ch2)\n",
    "ax[3].imshow(ch3)\n",
    "ax[0].set_title(\"Molecule\")\n",
    "\n",
    "# ax[1, 1].set_title(\"Gasteiger Charge Channel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The featurization is working correctly, we proceed to model building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was adpoted directly from the paper with `N` being selected as `32`\n",
    "\n",
    "### `Block Architecture`\n",
    "![Alt text](images/model_block_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import Adam\n",
    "# model = Chemception(N=256, reductionA_count=0, reductionB_count=0)\n",
    "# model = model.build()\n",
    "# model.compile(optimizer=Adam(learning_rate=.05), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing generator and data for fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/Featurizer.png)\n",
    "It can be observed from the above image the orientation difference between the original image and our featurization result. Since our featurization method in recontructing the molecule image using our selected features, we can assure the `0` intra-class variation, hence, we do not need augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import Flatten\n",
    "\n",
    "# def Inception0(input):\n",
    "#     tower_1 = Conv2D(16, (1, 1), padding='same', activation='relu')(input)\n",
    "#     tower_1 = Conv2D(16, (3, 3), padding='same', activation='relu')(tower_1)\n",
    " \n",
    "#     tower_2 = Conv2D(16, (1, 1), padding='same', activation='relu')(input)\n",
    "#     tower_2 = Conv2D(16, (5, 5), padding='same', activation='relu')(tower_2)\n",
    " \n",
    "#     tower_3 = Conv2D(16, (1, 1), padding='same', activation='relu')(input)\n",
    " \n",
    "#     output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "#     return output\n",
    "\n",
    "# def Inception(input):\n",
    "#     tower_1 = Conv2D(16, (1, 1), padding='same', activation='relu')(input)\n",
    "#     tower_1 = Conv2D(16, (3, 3), padding='same', activation='relu')(tower_1)\n",
    " \n",
    "#     tower_2 = Conv2D(16, (1, 1), padding='same', activation='relu')(input)\n",
    "#     tower_2 = Conv2D(16, (5, 5), padding='same', activation='relu')(tower_2)\n",
    " \n",
    "#     tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input)\n",
    "#     tower_3 = Conv2D(16, (1, 1), padding='same', activation='relu')(tower_3)\n",
    " \n",
    "#     output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=-1)\n",
    "#     return output\n",
    "\n",
    "\n",
    "\n",
    "# input_img = Input(shape=X_train.shape[1:])\n",
    " \n",
    "# x = Inception0(input_img)\n",
    "# x = Inception(x)\n",
    "# x = Inception(x)\n",
    "# od=int(x.shape[1])\n",
    "# x = MaxPooling2D(pool_size=(od,od), strides=(1,1))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(100, activation='relu')(x)\n",
    "# output = Dense(1, activation='sigmoid')(x)\n",
    " \n",
    "# model = Model(inputs=input_img, outputs=output)\n",
    "# optimizer = Adam(lr=0.00025)\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "generator = ImageDataGenerator(data_format='channels_last')\n",
    "\n",
    "train_df.dropna(subset=[\"molimage\"], inplace=True)\n",
    "X_train = train_df[\"molimage\"].to_numpy()\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "y_train = train_df[\"label\"]\n",
    "\n",
    "batch_size=32\n",
    "g = generator.flow(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('data/val_aid686978_0.3.csv')\n",
    "# val_df = val_df.sample(frac=0.2)\n",
    "val_df['mol'] = val_df['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "val_df['molimage'] = val_df['mol'].apply(featureizer.featurize)\n",
    "val_df.dropna(subset=[\"molimage\"], inplace=True)\n",
    "X_val = val_df[\"molimage\"].to_numpy()\n",
    "X_val = np.stack(X_val, axis=0)\n",
    "y_val = val_df[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimal config from hyperband and baysian optimization\n",
    "{'config': {'dense_layers': 3,\n",
    "  'dropout': 0.2,\n",
    "  'embed': 25,\n",
    "  'lr': 5e-06,\n",
    "  'neurons': 256},\n",
    " 'config_info': {'model_based_pick': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 80, 80, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 39, 39, 32)   864         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 39, 39, 32)  96          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 39, 39, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 37, 37, 32)   9216        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 37, 37, 32)  96          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 37, 37, 32)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 37, 37, 64)   18432       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 37, 37, 64)  192         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 37, 37, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 18, 18, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 18, 18, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 18, 18, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 18, 18, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 16, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 192)   0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 7, 7, 48)     9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 7, 7, 96)     55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 7, 7, 48)    144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 7, 7, 96)    288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 7, 7, 48)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 7, 7, 96)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 7, 7, 192)   0           ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 7, 7, 64)     12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 7, 7, 64)     76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 7, 7, 32)     6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 7, 7, 64)    192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 7, 7, 96)    288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 7, 7, 32)    96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 7, 7, 32)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 7, 7, 256)    0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 7, 7, 64)    192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 7, 7, 48)     12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 7, 7, 48)    144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 7, 7, 96)    288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 7, 7, 256)   0           ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 7, 7, 64)     16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 7, 7, 64)     16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 7, 7, 64)    192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 7, 7, 64)    192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 7, 7, 96)    288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 7, 7, 64)    192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 7, 7, 288)    0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 7, 7, 64)    192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 7, 7, 48)     13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 7, 7, 48)    144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 7, 7, 96)    288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 7, 7, 48)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 7, 7, 288)   0           ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 7, 7, 64)     76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 7, 7, 64)     18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 7, 7, 64)    192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 7, 7, 64)    192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 7, 7, 96)    288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 7, 7, 64)    192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 7, 7, 288)    0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 7, 7, 64)     18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 7, 7, 64)    192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 7, 7, 64)     0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 7, 7, 96)     55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 7, 7, 96)    288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 3, 3, 384)    995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 3, 3, 96)     82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 3, 3, 96)    288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 3, 3, 96)     0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 3, 3, 288)   0           ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 3, 3, 768)    0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 3, 3, 128)   384         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 3, 3, 128)   384         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 3, 3, 128)    98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 3, 3, 128)   384         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 3, 3, 128)   384         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 3, 3, 128)    114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 3, 3, 128)   384         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 3, 3, 128)   384         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 3, 3, 128)    0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 3, 3, 768)   0           ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 3, 3, 192)    172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 3, 3, 192)   576         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 3, 3, 192)   576         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 3, 3, 192)   576         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 3, 3, 192)   576         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 3, 3, 768)    0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 3, 3, 160)   480         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 3, 3, 160)   480         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 3, 3, 160)   480         ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 3, 3, 160)   480         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 3, 3, 160)   480         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 3, 3, 160)   480         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 3, 3, 768)   0           ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 3, 3, 192)   576         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 3, 3, 192)   576         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 3, 3, 192)   576         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 3, 3, 192)   576         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 3, 3, 768)    0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 3, 3, 160)   480         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 3, 3, 160)   480         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 3, 3, 160)    122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 3, 3, 160)   480         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 3, 3, 160)   480         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 3, 3, 160)    179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 3, 3, 160)   480         ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 3, 3, 160)   480         ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 3, 3, 160)    0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 3, 3, 768)   0           ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 3, 3, 192)    215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 3, 3, 192)   576         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 3, 3, 192)   576         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 3, 3, 192)   576         ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 3, 3, 192)   576         ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 3, 3, 768)    0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 3, 3, 192)   576         ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 3, 3, 192)   576         ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 3, 3, 192)   576         ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 3, 3, 192)   576         ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 3, 3, 192)   576         ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 3, 3, 192)   576         ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 3, 3, 768)   0           ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 3, 3, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 3, 3, 192)   576         ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 3, 3, 192)   576         ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 3, 3, 192)   576         ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 3, 3, 192)   576         ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 3, 3, 768)    0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 3, 3, 192)   576         ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 3, 3, 192)   576         ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 3, 3, 192)    147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 3, 3, 192)    258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 3, 3, 192)   576         ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 3, 3, 192)   576         ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 1, 1, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 1, 1, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 1, 1, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 1, 1, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 1, 1, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 1, 1, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 1, 1, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 1, 1, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 1, 1, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 1, 1, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 1, 1, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 1, 1, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 1, 1, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1, 1, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 1, 1, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 1, 1, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 1, 1, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 1, 1, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 1, 1, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 1, 1, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 1, 1, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 1, 1, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 1, 1, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 1, 1, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 1, 1, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 1, 1, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 1, 1, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 1, 1, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 1, 1, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 1, 1, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 1, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 1, 1, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 1, 1, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         2098176     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            1025        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,901,985\n",
      "Trainable params: 2,099,201\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from chemception.chemception_transfer import Chemception\n",
    "from keras.optimizers import Adam\n",
    "model = Chemception(neurons=512, dropout=0.0, dense_layers=1, img_size=80)\n",
    "model = model.build()\n",
    "model.compile(optimizer=Adam(learning_rate= 0.5e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "\n",
    "# Define the input shape for your data\n",
    "input_shape = (80, 80, 3)\n",
    "\n",
    "# Load the InceptionV3 model, excluding the top layers\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully-connected layer with 512 hidden units and ReLU activation\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Add a final output layer with sigmoid activation for binary classification\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the transfer learning model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the weights of all layers in the InceptionV3 model except the last two\n",
    "for layer in base_model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 05:32:14.383187: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409/409 [==============================] - 22s 47ms/step - loss: 0.6850 - accuracy: 0.6031 - val_loss: 0.6468 - val_accuracy: 0.6243\n",
      "Epoch 2/50\n",
      "409/409 [==============================] - 17s 40ms/step - loss: 0.6512 - accuracy: 0.6207 - val_loss: 0.6420 - val_accuracy: 0.6443\n",
      "Epoch 3/50\n",
      "409/409 [==============================] - 16s 40ms/step - loss: 0.6474 - accuracy: 0.6264 - val_loss: 0.6471 - val_accuracy: 0.6320\n",
      "Epoch 4/50\n",
      "409/409 [==============================] - 17s 42ms/step - loss: 0.6449 - accuracy: 0.6307 - val_loss: 0.6410 - val_accuracy: 0.6379\n",
      "Epoch 5/50\n",
      "409/409 [==============================] - 128s 314ms/step - loss: 0.6458 - accuracy: 0.6281 - val_loss: 0.6405 - val_accuracy: 0.6334\n",
      "Epoch 6/50\n",
      "209/409 [==============>...............] - ETA: 8s - loss: 0.6426 - accuracy: 0.6384"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      2\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(g, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(X_train)\u001b[39m/\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto', restore_best_weights=True)\n",
    "model.fit(g, epochs=50, steps_per_epoch=len(X_train)/64, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "model.save('chemception_transfer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# steps_per_epoch = X_train.shape[0]//batch_size\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=1e-6, verbose=1)\n",
    "\n",
    "\n",
    "# history = model.fit(g,\n",
    "#                     steps_per_epoch=steps_per_epoch,\n",
    "#                     epochs=100, verbose=2,\n",
    "#                     validation_data=(X_val, y_val),\n",
    "#                     callbacks=[reduce_lr]\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(g, epochs=200, steps_per_epoch=len(X_train)/64, validation_data=(X_val, y_val))\n",
    "model.save('chemception_transfer_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 2s 26ms/step - loss: 0.6450 - accuracy: 0.6260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6449547410011292, 0.6260032057762146]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39myscale(\u001b[39m\"\u001b[39m\u001b[39mlog\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:29:03] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/test_aid686978_0.3.csv')\n",
    "# test_df = test_df.sample(frac=0.2)\n",
    "test_df['mol'] = test_df['smiles'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "test_df['molimage'] = test_df['mol'].apply(featureizer.featurize)\n",
    "test_df.dropna(subset=[\"molimage\"], inplace=True)\n",
    "X_test = np.array(list(test_df[\"molimage\"]))\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 1s 15ms/step - loss: 0.6931 - accuracy: 0.5033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.693132221698761, 0.5032538175582886]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing other models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8079477782867613"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from deepchem.feat import CircularFingerprint\n",
    "\n",
    "featurizer = CircularFingerprint(size=1024)\n",
    "X_train, y_train = featurizer.featurize(train_df[\"smiles\"]), train_df[\"label\"]\n",
    "X_val, y_val = featurizer.featurize(val_df[\"smiles\"]), val_df[\"label\"]\n",
    "# X_test, y_test = featurizer.featurize(test_df[\"smiles\"]), test_df[\"label\"]\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and' defined at (most recent call last):\n    File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 985, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/7n/ynz1z7qd3fbg7568r_zgsb980000gn/T/ipykernel_43252/2823185961.py\", line 12, in <module>\n      model.fit(dataset)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 351, in fit\n      return self.fit_generator(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 441, in fit_generator\n      batch_loss = apply_gradient_for_batch(inputs, labels, weights, loss)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 507, in apply_gradient_for_batch\n      grads = tape.gradient(batch_loss, vars)\nNode: 'gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and'\nNo registered 'BroadcastTo' OpKernel for 'GPU' devices compatible with node {{node gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_BOOL, Tidx=DT_INT32, _XlaHasReferenceVars=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"\n\t.  Registered:  device='XLA_CPU_JIT'; Tidx in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 930109355527764061, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN]\n  device='GPU'; T in [DT_FLOAT]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n\n\t [[gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and]] [Op:__inference_apply_gradient_for_batch_55543]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m dataset \u001b[39m=\u001b[39m dc\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mNumpyDataset(X_train, y_train)\n\u001b[1;32m     11\u001b[0m model \u001b[39m=\u001b[39m GraphConvModel(n_tasks\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m'\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset)\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mevaluate(dataset)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py:351\u001b[0m, in \u001b[0;36mKerasModel.fit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m         dataset: Dataset,\n\u001b[1;32m    304\u001b[0m         nb_epoch: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m         callbacks: Union[Callable, List[Callable]] \u001b[39m=\u001b[39m [],\n\u001b[1;32m    312\u001b[0m         all_losses: Optional[List[\u001b[39mfloat\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m    313\u001b[0m   \u001b[39m\"\"\"Train this model on a dataset.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \n\u001b[1;32m    315\u001b[0m \u001b[39m  Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m  The average loss over the most recent checkpoint interval\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m \"\"\"\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_generator(\n\u001b[1;32m    352\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_generator(dataset,\n\u001b[1;32m    353\u001b[0m                              epochs\u001b[39m=\u001b[39;49mnb_epoch,\n\u001b[1;32m    354\u001b[0m                              deterministic\u001b[39m=\u001b[39;49mdeterministic),\n\u001b[1;32m    355\u001b[0m       max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss,\n\u001b[1;32m    356\u001b[0m       callbacks, all_losses)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py:441\u001b[0m, in \u001b[0;36mKerasModel.fit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    439\u001b[0m   inputs \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 441\u001b[0m batch_loss \u001b[39m=\u001b[39m apply_gradient_for_batch(inputs, labels, weights, loss)\n\u001b[1;32m    442\u001b[0m current_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_global_step\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    444\u001b[0m avg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and' defined at (most recent call last):\n    File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/miniconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 985, in launch_instance\n      app.start()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/opt/miniconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/7n/ynz1z7qd3fbg7568r_zgsb980000gn/T/ipykernel_43252/2823185961.py\", line 12, in <module>\n      model.fit(dataset)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 351, in fit\n      return self.fit_generator(\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 441, in fit_generator\n      batch_loss = apply_gradient_for_batch(inputs, labels, weights, loss)\n    File \"/opt/miniconda3/lib/python3.9/site-packages/deepchem/models/keras_model.py\", line 507, in apply_gradient_for_batch\n      grads = tape.gradient(batch_loss, vars)\nNode: 'gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and'\nNo registered 'BroadcastTo' OpKernel for 'GPU' devices compatible with node {{node gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_BOOL, Tidx=DT_INT32, _XlaHasReferenceVars=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"\n\t.  Registered:  device='XLA_CPU_JIT'; Tidx in [DT_INT32, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 930109355527764061, DT_HALF, DT_UINT32, DT_UINT64, DT_FLOAT8_E5M2, DT_FLOAT8_E4M3FN]\n  device='GPU'; T in [DT_FLOAT]\n  device='DEFAULT'; T in [DT_INT32]\n  device='CPU'; T in [DT_UINT64]\n  device='CPU'; T in [DT_INT64]\n  device='CPU'; T in [DT_UINT32]\n  device='CPU'; T in [DT_UINT16]\n  device='CPU'; T in [DT_INT16]\n  device='CPU'; T in [DT_UINT8]\n  device='CPU'; T in [DT_INT8]\n  device='CPU'; T in [DT_INT32]\n  device='CPU'; T in [DT_HALF]\n  device='CPU'; T in [DT_BFLOAT16]\n  device='CPU'; T in [DT_FLOAT]\n  device='CPU'; T in [DT_DOUBLE]\n  device='CPU'; T in [DT_COMPLEX64]\n  device='CPU'; T in [DT_COMPLEX128]\n  device='CPU'; T in [DT_BOOL]\n  device='CPU'; T in [DT_STRING]\n  device='CPU'; T in [DT_RESOURCE]\n  device='CPU'; T in [DT_VARIANT]\n\n\t [[gradient_tape/private__graph_conv_keras_model_6/graph_gather_6/and]] [Op:__inference_apply_gradient_for_batch_55543]"
     ]
    }
   ],
   "source": [
    "from deepchem.models import GraphConvModel\n",
    "from deepchem.feat import ConvMolFeaturizer\n",
    "import deepchem as dc\n",
    "\n",
    "featurizer = ConvMolFeaturizer()\n",
    "X_train, y_train = featurizer.featurize(train_df[\"smiles\"]), train_df[\"label\"]\n",
    "X_val, y_val = featurizer.featurize(val_df[\"smiles\"]), val_df[\"label\"]\n",
    "# X_test, y_test = featurizer.featurize(test_df[\"smiles\"]), test_df[\"label\"]\n",
    "\n",
    "dataset = dc.data.NumpyDataset(X_train, y_train)\n",
    "model = GraphConvModel(n_tasks=1, mode='classification', dropout=0.2)\n",
    "model.fit(dataset)\n",
    "\n",
    "model.evaluate(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
